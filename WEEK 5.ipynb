{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaecf9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d4a73",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 9] Bad file descriptor",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[31mOSError\u001b[39m: [Errno 9] Bad file descriptor",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      9\u001b[39m movies_data = {\u001b[33m\"\u001b[39m\u001b[33mName\u001b[39m\u001b[33m\"\u001b[39m : [\u001b[33m\"\u001b[39m\u001b[33mDangal\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mInterception\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDead Poets Society\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mInterstellar\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDilwale Dulhaniya le Jaenge\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTennet\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m500 Days of Summer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFight Club\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mI Want to eat your Pancreas\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mYour Lie in April\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     10\u001b[39m               \u001b[33m\"\u001b[39m\u001b[33mLanguage\u001b[39m\u001b[33m\"\u001b[39m : [\u001b[33m\"\u001b[39m\u001b[33mHindi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEnglish\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEnglish\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEnglish\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHindi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEnglish\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEnglish\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEnglish\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mJapanese\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mJapanese\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     11\u001b[39m               \u001b[33m\"\u001b[39m\u001b[33mGenre\u001b[39m\u001b[33m\"\u001b[39m : [\u001b[33m\"\u001b[39m\u001b[33mSports\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mThriller\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDrama\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSci-Fi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRomance\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSci-Fi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRomance\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAction\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRomance\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRomance\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     12\u001b[39m               \u001b[33m\"\u001b[39m\u001b[33mRating\u001b[39m\u001b[33m\"\u001b[39m : [\u001b[32m9.0\u001b[39m, \u001b[32m9.5\u001b[39m, \u001b[32m9.8\u001b[39m, \u001b[32m9.9\u001b[39m, \u001b[32m9.5\u001b[39m, \u001b[32m9.7\u001b[39m, \u001b[32m9.8\u001b[39m, \u001b[32m8.9\u001b[39m, \u001b[32m10.0\u001b[39m, \u001b[32m9.5\u001b[39m],\n\u001b[32m     13\u001b[39m               \u001b[33m\"\u001b[39m\u001b[33mReview\u001b[39m\u001b[33m\"\u001b[39m : [\u001b[33m\"\u001b[39m\u001b[33mExcellent\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAmazing\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mExtra Ordinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mJust marvellous\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRomantic Masterpiece\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mVisually Stunning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mExquisitely Beautiful\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAction Packed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPeak of Romance Anime\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCan make you cry\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m     15\u001b[39m df_movie = pd.DataFrame(movies_data)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mdf_movie\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMovie.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mMovie.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Baladitya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Baladitya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Baladitya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Baladitya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Note: self.encoding is irrelevant here\u001b[39;49;00m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsvlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Baladitya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:157\u001b[39m, in \u001b[36mIOHandles.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__exit__\u001b[39m(\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    153\u001b[39m     exc_type: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mBaseException\u001b[39;00m] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    154\u001b[39m     exc_value: \u001b[38;5;167;01mBaseException\u001b[39;00m | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    155\u001b[39m     traceback: TracebackType | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    156\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Baladitya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:144\u001b[39m, in \u001b[36mIOHandles.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28mself\u001b[39m.created_handles.remove(\u001b[38;5;28mself\u001b[39m.handle)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.created_handles:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[43mhandle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28mself\u001b[39m.created_handles = []\n\u001b[32m    146\u001b[39m \u001b[38;5;28mself\u001b[39m.is_wrapped = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 9] Bad file descriptor"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies_data = {\n",
    "    \"Name\": [\"Dangal\", \"Interception\", \"Dead Poets Society\", \n",
    "             \"Interstellar\", \"Dilwale Dulhaniya le Jaenge\", \n",
    "             \"Tennet\", \"500 Days of Summer\", \"Fight Club\", \n",
    "             \"I Want to eat your Pancreas\", \"Your Lie in April\"],\n",
    "    \n",
    "    \"Language\": [\"Hindi\", \"English\", \"English\", \"English\", \n",
    "                 \"Hindi\", \"English\", \"English\", \"English\", \n",
    "                 \"Japanese\", \"Japanese\"],\n",
    "    \n",
    "    \"Genre\": [\"Sports\", \"Thriller\", \"Drama\", \"Sci-Fi\", \n",
    "              \"Romance\", \"Sci-Fi\", \"Romance\", \"Action\", \n",
    "              \"Romance\", \"Romance\"],\n",
    "    \n",
    "    \"Rating\": [9.0, 9.5, 9.8, 9.9, 9.5, 9.7, 9.8, 8.9, 10.0, 9.5],\n",
    "    \n",
    "    \"Review\": [\"Excellent\", \"Amazing\", \"Extra Ordinary\", \n",
    "               \"Just marvellous\", \"Romantic Masterpiece\", \n",
    "               \"Visually Stunning\", \"Exquisitely Beautiful\", \n",
    "               \"Action Packed\", \"Peak of Romance Anime\", \n",
    "               \"Can make you cry\"]\n",
    "}\n",
    "print(\"HELLO FUCKFACE\")\n",
    "# Create dataframe\n",
    "df_movie = pd.DataFrame(movies_data)\n",
    "\n",
    "# Save to CSV\n",
    "df_movie.to_csv(\"Movies.csv\", index=False)\n",
    "\n",
    "# Read CSV\n",
    "df = pd.read_csv(\"Movies.csv\")\n",
    "\n",
    "# Highest rated movie\n",
    "highest_rated = df.loc[df[\"Rating\"].idxmax(), \"Name\"]\n",
    "print(\"The highest rated movie is:\", highest_rated)\n",
    "\n",
    "# Filter Hindi movies\n",
    "hindi_movies = df[df[\"Language\"] == \"Hindi\"]\n",
    "\n",
    "# Save Hindi movies\n",
    "hindi_movies.to_csv(\"HindiMovies.csv\", index=False)\n",
    "\n",
    "print(\"Separate CSV file for Hindi Movies created successfully.\")\n",
    "\n",
    "# Read and display Hindi movies\n",
    "df_hindi = pd.read_csv(\"HindiMovies.csv\")\n",
    "print(df_hindi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923845f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         protein        fat       sodium      fiber      carbo     sugars  \\\n",
      "count   9.000000   9.000000     9.000000   9.000000   9.000000   9.000000   \n",
      "mean    5.375000   2.750000   263.333333   6.777778  15.444444  10.333333   \n",
      "std     5.677532   3.072051   287.847616   9.337797  13.538012  11.651180   \n",
      "min     2.000000   0.000000    15.000000   1.000000   5.000000   1.000000   \n",
      "25%     2.000000   1.000000   130.000000   2.000000   8.000000   5.000000   \n",
      "50%     4.000000   2.000000   200.000000   2.000000  12.000000   6.000000   \n",
      "75%     5.375000   2.750000   260.000000   9.000000  15.000000   8.000000   \n",
      "max    20.000000  10.000000  1000.000000  30.000000  50.000000  40.000000   \n",
      "\n",
      "            potass    vitamins  \n",
      "count     9.000000    9.000000  \n",
      "mean    260.625000   30.555556  \n",
      "std     293.954051   27.322661  \n",
      "min      30.000000    0.000000  \n",
      "25%     105.000000   25.000000  \n",
      "50%     135.000000   25.000000  \n",
      "75%     280.000000   25.000000  \n",
      "max    1000.000000  100.000000  \n",
      "         protein        fat       sodium      fiber      carbo     sugars  \\\n",
      "count   9.000000   9.000000     9.000000   9.000000   9.000000   9.000000   \n",
      "mean    5.375000   2.750000   263.333333   6.777778  15.444444  10.333333   \n",
      "std     5.677532   3.072051   287.847616   9.337797  13.538012  11.651180   \n",
      "min     2.000000   0.000000    15.000000   1.000000   5.000000   1.000000   \n",
      "25%     2.000000   1.000000   130.000000   2.000000   8.000000   5.000000   \n",
      "50%     4.000000   2.000000   200.000000   2.000000  12.000000   6.000000   \n",
      "75%     5.375000   2.750000   260.000000   9.000000  15.000000   8.000000   \n",
      "max    20.000000  10.000000  1000.000000  30.000000  50.000000  40.000000   \n",
      "\n",
      "            potass  vitamins  \n",
      "count     9.000000       9.0  \n",
      "mean    260.625000      25.0  \n",
      "std     293.954051       0.0  \n",
      "min      30.000000      25.0  \n",
      "25%     105.000000      25.0  \n",
      "50%     135.000000      25.0  \n",
      "75%     280.000000      25.0  \n",
      "max    1000.000000      25.0  \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Question 2 : For the CEREALS dataset, perform data preprocessing and \n",
    "answer the following questions. \n",
    "a. Create a table with the 5 number summary of all the numeric \n",
    "attributes. \n",
    "b. For each of the numeric attributes (proteins upto vitamins) , \n",
    "identify and replace all missing data(indicated with -1) with \n",
    "the arithmetic mean of the attribute. \n",
    "c. Create a table with the 5 number summary of all the numeric \n",
    "attributes after treating missing values. Do you think the \n",
    "strategy used in dealing with missing values was effective? \n",
    "d. For each numeric attribute (proteins upto vitamins), identify \n",
    "and replace all noisy data with the median of attribute. \n",
    "e. Create a table with the 5 number summary of all the numeric \n",
    "attributes after treating noisy values. Do you think the \n",
    "strategy used in dealing with noisy values was effective? \"\"\"\n",
    "\n",
    "df = pd.read_csv(\"cereal5255.csv\")\n",
    "df.describe()\n",
    "numeric_cols = df.loc[:, \"protein\":\"vitamins\"]\n",
    "df_mean = df.copy()\n",
    "for col in numeric_cols.columns:\n",
    "    mean_value = df_mean.loc[df_mean[col] != -1, col].mean()\n",
    "    df_mean[col] = df_mean[col].replace(-1, mean_value)\n",
    "print(df_mean.loc[:, \"protein\":\"vitamins\"].describe())\n",
    "df_median  = df_mean.copy()\n",
    "for col in numeric_cols.columns:\n",
    "    median_value = df_median[col].median()\n",
    "    q1 = df_median[col].quantile(0.25)\n",
    "    q3 = df_median[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5*iqr\n",
    "    upper = q3 + 1.5*iqr\n",
    "    df_median.loc[(df_median[col] < lower) | (df_median[col] > upper), col] = median_value\n",
    "print(df_median.loc[:, \"protein\":\"vitamins\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a2b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
